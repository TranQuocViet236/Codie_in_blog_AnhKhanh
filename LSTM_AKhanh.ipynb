{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_AKhanh.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMXiNqIDa4UGaoAVeD5zXh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranQuocViet236/Codie_in_blog_AnhKhanh/blob/master/LSTM_AKhanh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_6WPpdccIH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAt21n89dLil"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLMjCg1iGXdf"
      },
      "source": [
        "PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew_hUIR2dr6h"
      },
      "source": [
        "filename = '/content/gdrive/MyDrive/ML/LSTM/wonderland.txt'\n",
        "#convert lower texts to reduce data size\n",
        "raw_text = open(filename).read().lower()\n",
        "print(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmGF25voeS9C"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "print(f'number of letters: {len(char_to_int)}')\n",
        "print(char_to_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQMiIferej98"
      },
      "source": [
        "import string\n",
        "string.ascii_lowercase\n",
        "\n",
        "chars_new = list(string.ascii_lowercase) + ['0', '.', ',', ' ', '!', '?', 'unk'  ]\n",
        "chars_to_int = dict((v,k) for k,v in enumerate(chars_new))\n",
        "int_to_chars = dict((k,v) for k,v in enumerate(chars_new))\n",
        "\n",
        "print('character to int: ', chars_to_int)\n",
        "print('int to character: ', int_to_chars)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQMmDI2lEuv9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khgpM59YjeYI"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars_new)\n",
        "\n",
        "print('Total characters: ', n_chars)\n",
        "print('Total vocab: ', n_vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_hbcwWPGEqz"
      },
      "source": [
        "After, standardizing texts, we have 13637 words and 33 character\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwaCwj8XF-yi"
      },
      "source": [
        "def _encode_sen(text):\n",
        "  text = text.lower()\n",
        "  sen_vec = []\n",
        "  for let in text:\n",
        "    if let in chars_new[:-1]:\n",
        "      idx = chars_to_int[let]\n",
        "    else:\n",
        "      idx = chars_to_int['unk']\n",
        "    sen_vec.append(idx)\n",
        "  return sen_vec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHJNt9J-HJM-"
      },
      "source": [
        "print(chars_new[:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBsyFNgHHOqQ"
      },
      "source": [
        "print(char_to_int['q'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm3Z7jVNHcoJ"
      },
      "source": [
        "x_test = _encode_sen('Alice is a wonderful story.#')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HgSJA1QHoJE"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0KQHz0dHqLc"
      },
      "source": [
        "def _decode_sen(vec):\n",
        "  text = []\n",
        "  for i in vec:\n",
        "    let  = int_to_chars[i]\n",
        "    text.append(let)\n",
        "  text = ''.join(text)\n",
        "  return text\n",
        "   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AV6L4WbJF2O"
      },
      "source": [
        "_decode_sen(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P6fnrRzJISK"
      },
      "source": [
        "#prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX  = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  #Get 100 previous characters \n",
        "  seq_in = raw_text[i:i+ seq_length]\n",
        "  #Get the character after that 100 character\n",
        "  seq_out = raw_text[i+ seq_length]\n",
        "\n",
        "  dataX.append(_encode_sen(seq_in))\n",
        "  dataY.append(_encode_sen(seq_out[0]))\n",
        "  n_patterns = len(dataX)\n",
        "print('Total Patterns: ', n_patterns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVFeLra7NMt1"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X_train = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "#Nomalize \n",
        "X_train = X_train/ float(n_vocab)\n",
        "#one hot encode the output variable \n",
        "y_train = np_utils.to_categorical(dataY)\n",
        "\n",
        "print(f'X[sample, time steps, features] shape: {X_train.shape}')\n",
        "print(f'Y shape: {y_train.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7p-a_6kKNh3"
      },
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldEsxjbPlu3"
      },
      "source": [
        "Data visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA1iiuEtPgGB"
      },
      "source": [
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "\n",
        "# print(dataY)\n",
        "# print(len(dataY))\n",
        "# plt.figure(figsize = (10,5))\n",
        "# sns.countplot((np.array(dataY)))\n",
        "# plt.xticks(np.arange(32), np.array(chars_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtGZiZR4Un-K"
      },
      "source": [
        "Build a model to predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pw41IakVAr3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EthU1ADQZqb"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape= (X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTI4Vh3DV2Nh"
      },
      "source": [
        "filepath = 'weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callback_list = [checkpoint]\n",
        "model.fit(X_train, y_train, epochs = 5, batch_size = 128, validation_split=0.33, callbacks = callback_list, verbose = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EeTN3miWucw"
      },
      "source": [
        "import numpy as np\n",
        "base_word = 'Alice was beginning to get very tired of sitting by her sister on the bank'\n",
        "\n",
        "def _predict_let(text, len_sen = 1):\n",
        "  text_for = []\n",
        "  for i in range(len_sen):\n",
        "    x_input = np.array(_encode_sen(text)[-100:])/float(n_vocab)\n",
        "    if x_input.shape[0] < 100:\n",
        "      x_input = np.concatenate((np.zeros(100-x_input.shape[0]), x_input), axis = 0)\n",
        "    x_input = np.expand_dims(np.expand_dims(x_input, -1), 0)\n",
        "    y_prob = model.predict(x_input)\n",
        "    y_let = int_to_chars[np.argmax(y_prob, axis=1)[0]]\n",
        "    text = text + y_let\n",
        "  return text[len_sen:]\n",
        "_predict_let(base_word,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9f_XWBcCN2"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juqNsNZwdRy2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}